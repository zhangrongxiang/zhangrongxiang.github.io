<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Attention is all I needï¼šTransformerçš„åŸç†å’Œä»£ç è¯¦è§£ | JackZhang's Blog</title><meta name="author" content="JackZhang"><meta name="copyright" content="JackZhang"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="attentionæœºåˆ¶ï¼ŒattentionåŸç†ï¼ŒTransformeråŸç†ï¼ŒTransformerä»£ç "><meta property="og:type" content="article"><meta property="og:title" content="Attention is all I needï¼šTransformerçš„åŸç†å’Œä»£ç è¯¦è§£"><meta property="og:url" content="https://www.jkzhang.ml/2025/02/20/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%9C%80%E4%BC%98%E5%85%AC%E5%BC%8F/index.html"><meta property="og:site_name" content="JackZhang&#39;s Blog"><meta property="og:description" content="attentionæœºåˆ¶ï¼ŒattentionåŸç†ï¼ŒTransformeråŸç†ï¼ŒTransformerä»£ç "><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><meta property="article:published_time" content="2025-02-20T09:00:00.000Z"><meta property="article:modified_time" content="2025-02-22T08:38:37.553Z"><meta property="article:author" content="JackZhang"><meta property="article:tag" content="deep learning"><meta property="article:tag" content="transformers"><meta property="article:tag" content="attention"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://www.jkzhang.ml/2025/02/20/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%9C%80%E4%BC%98%E5%85%AC%E5%BC%8F/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:void 0,translate:void 0,noticeOutdate:void 0,highlight:void 0,copy:{success:"å¤åˆ¶æˆåŠŸ",error:"å¤åˆ¶é”™è¯¯",noSupport:"æµè§ˆå™¨ä¸æ”¯æŒ"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"åˆšåˆš",min:"åˆ†é’Ÿå‰",hour:"å°æ—¶å‰",day:"å¤©å‰",month:"ä¸ªæœˆå‰"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js",buttonText:"åŠ è½½æ›´å¤š"},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Attention is all I needï¼šTransformerçš„åŸç†å’Œä»£ç è¯¦è§£",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2025-02-22 16:38:37"}</script><script>(e=>{e.saveToLocal={set:(e,t,a)=>{0!==a&&(a={value:t,expiry:Date.now()+864e5*a},localStorage.setItem(e,JSON.stringify(a)))},get:e=>{var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!(Date.now()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=(o,n={})=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},Object.keys(n).forEach(e=>{a.setAttribute(e,n[e])}),document.head.appendChild(a)}),e.getCSS=(o,n=!1)=>new Promise((t,e)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme");"dark"===e?activateDarkMode():"light"===e&&activateLightMode();e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="JackZhang's Blog" type="application/atom+xml"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s3.bmp.ovh/imgs/2024/06/07/50ea7f3f41ccf524.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">63</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">18</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg)"><nav id="nav"><span id="blog-info"><a href="/" title="JackZhang's Blog"><img class="site-icon" src="/img/favicon.ico"><span class="site-name">JackZhang's Blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Attention is all I needï¼šTransformerçš„åŸç†å’Œä»£ç è¯¦è§£</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2025-02-20T09:00:00.000Z" title="å‘è¡¨äº 2025-02-20 17:00:00">2025-02-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2025-02-22T08:38:37.553Z" title="æ›´æ–°äº 2025-02-22 16:38:37">2025-02-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Deep-Learning/">Deep Learning</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Deep-Learning/Transformers/">Transformers</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Attention is all I needï¼šTransformerçš„åŸç†å’Œä»£ç è¯¦è§£"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>Transformerå¯è¿è¡Œçš„ä»£ç å‘å¸ƒåœ¨<a target="_blank" rel="noopener" href="https://github.com/JinHanLei/Transformers_tutorial">GitHub</a><br>{: .prompt-tip }</p></blockquote><p>æåˆ°ChatGPTçš„åŸç†ï¼Œå°±ç»•ä¸å¼€Transformerï¼ŒTransformerä¸­çš„æ ¸å¿ƒæ€æƒ³ä¹‹ä¸€ä¾¿æ˜¯<strong>Attention</strong>ï¼ŒAttentionæœºåˆ¶å½»åº•å‡»è´¥äº†åœ¨æ­¤ä¹‹å‰çš„ç»å¯¹ç‹è€…RNNæ¨¡å¼ï¼Œå¹¶ç»Ÿæ²»å„å¤§NLPä»»åŠ¡ç›´åˆ°ç°åœ¨ã€‚æ­£å› å¦‚æ­¤ï¼ŒTransformerçš„è®ºæ–‡ä¸å«Transformerï¼Œè€Œæ˜¯å«åš<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">ã€ŠAttention is all you needã€‹</a>ã€‚æœ¬æ–‡æ˜¯ä»¥æˆ‘çš„ç†è§£ï¼Œé˜è¿°Transformeræ˜¯æ€ä¹ˆæƒ³å‡ºæ¥çš„ï¼Œä¸ºä»€ä¹ˆè¿™ä¹ˆè®¾è®¡ã€‚</p><h2 id="Attentionçš„æ€æƒ³"><a href="#Attentionçš„æ€æƒ³" class="headerlink" title="Attentionçš„æ€æƒ³"></a>Attentionçš„æ€æƒ³</h2><p>Attentionçš„å…³é”®åœ¨äºç†è§£$$QKV$$ï¼Œå³Queryã€Keyå’ŒValueã€‚å¯ä»¥å°†Attentionæœºåˆ¶çœ‹ä½œä¸€ç§å¯»å€æ“ä½œï¼šå­˜å‚¨å™¨ä¸­å­˜æœ‰é”®Keyå’Œå€¼Valueï¼Œå½“å‰äº§ç”Ÿäº†ä¸€ä¸ªQueryçš„æŸ¥è¯¢ï¼Œè¦æŸ¥è¯¢å‡ºValueï¼Œé‚£ä¹ˆé¦–å…ˆéœ€è¦åŒ¹é…Queryå’ŒKeyçš„ç›¸ä¼¼åº¦ã€‚ä¸¾ä¸ªä¹Ÿè®¸ä¸æ°å½“ï¼Œä½†ç›´è§‚çš„ä¾‹å­ï¼Œæœ‰ä»¥ä¸‹Keyå’ŒValueï¼š</p><table><thead><tr><th align="center">Key</th><th align="center">Value</th></tr></thead><tbody><tr><td align="center">æ®µèª‰çš„æ‹›ç‰Œæ­¦åŠŸ</td><td align="center">å…­è„‰ç¥å‰‘</td></tr><tr><td align="center">æ®µèª‰çš„ç”Ÿçˆ¶</td><td align="center">æ®µå»¶åº†</td></tr><tr><td align="center">æ®µèª‰çš„ç»“æ‹œå…„å¼Ÿ</td><td align="center">ä¹”å³°å’Œè™šç«¹</td></tr><tr><td align="center">ä¹”å³°çš„æ‹›ç‰Œæ­¦åŠŸ</td><td align="center">é™é¾™åå…«ç« </td></tr></tbody></table><p>å¯»å€æµç¨‹å¦‚ä¸‹ï¼š</p><ol><li>å‘èµ·Queryï¼šâ€œæ®µèª‰çš„ç”Ÿçˆ¶æ˜¯è°ï¼Ÿâ€</li><li>ä¸Keyç›¸ä¼¼åº¦åŒ¹é…åˆ°â€œæ®µèª‰çš„ç”Ÿçˆ¶â€</li><li>è¿”å›Valueâ€œæ®µå»¶åº†â€</li></ol><p>è¿™é‡Œçš„å…³é”®æ˜¯ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•ï¼Œé€šå¸¸æ˜¯Queryå’ŒKeyçš„çŸ©é˜µä¹˜æ³•ï¼Œæˆ–åŠ ä¸ªç¼©æ”¾$$\sqrt{d_k}$$ï¼Œæˆ–ä¹˜ä¸ª$$W$$ï¼Œå¦‚ä¸‹ï¼š</p><ul><li>çŸ©é˜µç›¸ä¹˜ï¼š$$sim(Q,K)=QK^T$$</li><li>ç›¸ä¹˜åŠ ç¼©æ”¾ï¼š$$sim(Q,K)=\frac{QK^T}{\sqrt{d_k}}$$ï¼ˆTransformerä½¿ç”¨ï¼Œç¼©æ”¾ä½¿å¾—è®­ç»ƒå¯ä»¥æ”¶æ•›ï¼‰</li><li>æƒé‡+æ¿€æ´»ï¼š$$sim(Q,K)=tanh(WQ+UK)$$</li><li>æƒé‡+ç›¸ä¹˜ï¼š$$sim(Q,K)=QWK^T$$</li></ul><p>å–å‡ºä¸€ä¸ªæˆ–è€…éƒ¨åˆ†Valueçš„æ–¹æ³•å«Hard Attentionï¼Œå¦‚ä¸Šä¾‹åªè¾“å‡ºâ€œæ®µå»¶åº†â€ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘é—®â€œæ®µèª‰ç»“æ‹œå…„å¼Ÿçš„æ‹›ç‰Œæ­¦åŠŸæ˜¯ä»€ä¹ˆï¼Ÿâ€ï¼ŒHard Attentionå¯èƒ½åŒ¹é…åˆ°â€œæ®µèª‰çš„ç»“æ‹œå…„å¼Ÿâ€ï¼Œè¾“å‡ºâ€œä¹”å³°å’Œè™šç«¹â€ï¼Œè¿™å°±ä¸å¯¹äº†ã€‚æ›¿ä»£æ–¹æ¡ˆå°±æ˜¯Soft Attentionï¼Œæä¾›æ‰€æœ‰Valueå’Œå¯¹åº”çš„Attentionæƒé‡ï¼Œå½“$$Q=$$â€œæ®µèª‰ç»“æ‹œå…„å¼Ÿçš„æ‹›ç‰Œæ­¦åŠŸæ˜¯ä»€ä¹ˆï¼Ÿâ€ï¼Œç»“æœå¯èƒ½å¦‚ä¸‹è¡¨ï¼š</p><table><thead><tr><th align="center">Key</th><th align="center">Attentionæƒé‡</th><th align="center">Value</th></tr></thead><tbody><tr><td align="center">æ®µèª‰çš„æ‹›ç‰Œæ­¦åŠŸ</td><td align="center">7</td><td align="center">å…­è„‰ç¥å‰‘</td></tr><tr><td align="center">æ®µèª‰çš„ç”Ÿçˆ¶</td><td align="center">1</td><td align="center">æ®µå»¶åº†</td></tr><tr><td align="center">æ®µèª‰çš„ç»“æ‹œå…„å¼Ÿ</td><td align="center">9</td><td align="center">ä¹”å³°å’Œè™šç«¹</td></tr><tr><td align="center">ä¹”å³°çš„æ‹›ç‰Œæ­¦åŠŸ</td><td align="center">5</td><td align="center">é™é¾™åå…«ç« </td></tr></tbody></table><p>è¿™æ ·ï¼Œå°±å¯ä»¥æŠŠé«˜åˆ†ç­”æ¡ˆç»“åˆï¼Œå¾—åˆ°æ­£ç¡®ç­”æ¡ˆã€‚å½“é—®é¢˜æ›´å®å¤§ï¼Œéœ€è¦çš„ä¿¡æ¯å°±æ›´å¤šï¼Œäºæ˜¯å¹²è„†æ¯æ¬¡éƒ½è¾“å‡ºæ•´å¼ è¡¨ï¼Œè™½ç„¶æœ‰å¯èƒ½å†—ä½™ï¼Œä½†è¿™æ ·å¾—åˆ°çš„ç­”æ¡ˆæ˜¯æ—¢æœ‰é‡ç‚¹ã€åˆå®Œæ•´çš„ã€‚</p><p>ä»¥å¾€è®¾å¤‡é™åˆ¶å¯¼è‡´è®¡ç®—å’Œè¾“å‡ºå…¨éƒ¨éå¸¸å›°éš¾ï¼Œä½†ç°åœ¨è®¾å¤‡çš„å‘å±•ä½¿å¾—è¶…å¤§è§„æ¨¡ã€è¶…é•¿æ–‡æœ¬è¾“å…¥çš„LLMå¾—ä»¥å‡ºç°ï¼Œè€ŒTransformerçš„self-attentionä¿è¯äº†LLMçš„æ•ˆç‡å’Œå­¦ä¹ èƒ½åŠ›ã€‚</p><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>Self-Attentionè¯´æ¥å¾ˆç®€å•ï¼Œå°±æ˜¯$$Q=K=V$$ã€‚</p><p>ä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšï¼Ÿä¸ªäººç†è§£æ˜¯è®©ä¸€å¥è¯å…ˆæ‰¾å‡ºè‡ªå·±å†…éƒ¨çš„å…³é”®è¯ï¼Œå†å»é€‚é…ä¸‹æ¸¸çš„ä»»åŠ¡ã€‚ä¾‹å¦‚$$Q=K=V=é’èŠ±ç“·$$ï¼Œç”¨Pytorchç®€å•è®¡ç®—å¦‚ä¸‹ï¼š</p><pre><code class="python">from torch import nn as nn
import torch
# &#123;é’:0, èŠ±:1, ç“·:2&#125;
tokens = torch.LongTensor([0, 1, 2])
# å°†3ä¸ªå­—è½¬æ¢æˆå‘é‡ï¼Œå‘é‡ç»´åº¦ä¸º10
token_embedding = nn.Embedding(3, 10)
emb = token_embedding(tokens)
# ç›¸ä¼¼åº¦è®¡ç®—
QK = torch.mm(emb, emb.T) / torch.sqrt(torch.FloatTensor([10]))
print(QK)
</code></pre><p>ç”±äºnn.Embeddingéšæœºåˆå§‹åŒ–ï¼Œæ‰€ä»¥ç»“æœä¼šä¸ä¸€æ ·ï¼Œæˆ‘çš„ç»“æœè¡¨è¿°å¦‚ä¸‹ï¼š</p><p>$$<br>sim(Q,K)=<br>\begin{bmatrix}<br>é’ &amp; èŠ± &amp; ç“·<br>\end{bmatrix}<br>\times<br>\begin{bmatrix}<br>é’\<br>èŠ±\<br>ç“·<br>\end{bmatrix}<br>/10<br>=<br>\begin{bmatrix}<br>3.2897 &amp; 0.7432 &amp; -1.1652 \<br>0.7432 &amp; 1.3647 &amp; -1.1707\<br>-1.1652 &amp; -1.1707 &amp; 5.6380<br>\end{bmatrix}<br>$$</p><p>çŸ©é˜µå¯¹è§’çº¿è¡¨ç¤ºè‡ªèº«çš„ç›¸ä¼¼åº¦ï¼Œæ¯”å¦‚3.2897å°±è¡¨ç¤ºâ€œé’â€å’Œâ€œé’â€çš„ç›¸ä¼¼åº¦ï¼Œå°±å¾ˆå¤§ã€‚æ¯è¡Œä»£è¡¨æ¯ä¸ªå­—çš„æƒé‡ã€‚ç”±äºç‚¹ç§¯å¯ä»¥äº§ç”Ÿä»»æ„å¤§çš„æ•°å­—ï¼Œè¿™ä¼šç ´åè®­ç»ƒè¿‡ç¨‹çš„ç¨³å®šæ€§ï¼Œå› æ­¤éœ€è¦ $$Softmax$$ã€‚Attentionçš„å…¬å¼è¡¨ç¤ºä¸ºï¼š</p><p>$$<br>\text{Attention}(Q, K, V) = \text{Softmax} \big( \frac{QK^T}{\sqrt{d_k}} \big)V<br>$$</p><p>ä»£ç åªé¡»å†åŠ ä¸Šï¼š</p><pre><code class="python">Attention = torch.mm(torch.softmax(QK, dim=-1), emb)
</code></pre><p>è¿™æ ·å¾—åˆ°çŸ©é˜µçš„æ¯è¡Œå°±è¡¨ç¤º[é’, èŠ±, ç“·]è¿™ä¸‰ä¸ªå­—çš„Attentionã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šæ›´æ–°è¿™äº›å‚æ•°ï¼Œä»è€Œæ ¹æ®ä¸Šä¸‹æ–‡å’Œæ ‡ç­¾å¾—åˆ°æ›´å¥½çš„å‘é‡è¡¨ç¤ºã€‚</p><h3 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h3><p>ä¸ºäº†å…³æ³¨åˆ°æ›´å¤šä¿¡æ¯ï¼ŒTransformeré‡‡ç”¨Multi-head Attentionæœºåˆ¶ï¼Œä¹Ÿå°±æ˜¯é‡å¤næ¬¡Attentionæ“ä½œç„¶åæ‹¼æ¥ï¼Œå¾—åˆ°å’ŒåŸæ¥çš„Attentionç»´åº¦ç›¸åŒçš„MultiHeadï¼Œå…¬å¼ä¸ºï¼š</p><p>$$<br>\begin{gather}head_i = \text{Attention}(\boldsymbol{Q}\boldsymbol{W}_i^Q,\boldsymbol{K}\boldsymbol{W}_i^K,\boldsymbol{V}\boldsymbol{W}_i^V)\\text{MultiHead}(\boldsymbol{Q},\boldsymbol{K},\boldsymbol{V}) = \text{Concat}(head_1,â€¦,head_h)\boldsymbol{W}^O\end{gather}<br>$$</p><p>å…¶ä¸­ $$\boldsymbol{W}<em>i^Q\in\mathbb{R}^{d</em>{model}\times d_k}, \boldsymbol{W}<em>i^K\in\mathbb{R}^{d</em>{model}\times d_k}, \boldsymbol{W}<em>i^V\in\mathbb{R}^{d</em>{model}\times d_v},\boldsymbol{W}^O\in\mathbb{R}^{hd_{v}\times d_{model}}$$ ã€‚</p><p>åŸæ–‡æ¨¡å‹çš„ç»´åº¦$$d_{model}$$æ˜¯512ï¼Œæˆ‘ä»¬è®¾ç½®$$h=8$$ä¸ªæ³¨æ„åŠ›å¤´ï¼Œé‚£ä¹ˆ$$d_k=d_v=d_{model}/h=64$$ã€‚æ¯ä¸ªæ³¨æ„åŠ›å¤´è´Ÿè´£å…³æ³¨æŸä¸€æ–¹é¢çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œå¤šä¸ªå¤´å°±å¯ä»¥è®©æ¨¡å‹åŒæ—¶å…³æ³¨å¤šä¸ªæ–¹é¢ã€‚ä¸æ€ä¹ˆä¸¥è°¨çš„ä»£ç å¦‚ä¸‹ï¼Œä¾¿äºç†è§£ï¼š</p><pre><code class="python">from torch import nn
import torch.nn.functional as F
from math import sqrt
import torch

class AttentionHead(nn.Module):
    def __init__(self, embed_dim, head_dim):
        super().__init__()
        self.WQ = nn.Linear(embed_dim, head_dim)
        self.WK = nn.Linear(embed_dim, head_dim)
        self.WV = nn.Linear(embed_dim, head_dim)

    def forward(self, query, key, value):
        QK = torch.mm(WQ(query), WK(key).T) / torch.sqrt(query.size(-1))
        Attention = torch.mm(torch.softmax(QK, dim=-1), WV(value))
        return Attention
    
class MultiHeadAttention(nn.Module):
    def __init__(self, config):
        super().__init__()
        embed_dim = config.hidden_size
        num_heads = config.num_attention_heads
        head_dim = embed_dim // num_heads
        self.heads = nn.ModuleList(
            [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)]
        )
        self.output_linear = nn.Linear(embed_dim, embed_dim)

    def forward(self, query, key, value):
        MultiHead = torch.cat([h(query, key, value) for h in self.heads], dim=-1)
        x = self.output_linear(MultiHead)
        return x
</code></pre><p>æ›´å¤šæ—¶å€™ï¼Œä¸ºäº†å¹¶è¡Œæ•ˆç‡ï¼Œå¤šå¤´æ“ä½œæ˜¯å…ˆä¹˜ä¸Š$$\boldsymbol{W}\in\mathbb{R}^{d_{model}\times d_{model}}$$çš„æƒé‡çŸ©é˜µï¼Œå†å°†QKVåˆ‡å—ç›¸ä¹˜ï¼ŒåŒä¸€ä¸ªç»“æœä½†æ˜¯æŠ›å¼ƒäº†<code>for</code>å¾ªç¯ï¼Œ<a target="_blank" rel="noopener" href="https://github.com/JinHanLei/Transformers_tutorial">æˆ‘çš„ä»“åº“</a>ä¸­å°±æ˜¯è¿™ç§åšæ³•ã€‚Transformeræœ€æ ¸å¿ƒçš„å°±æ˜¯ä¸Šæ–‡æ‰€è¿°çš„Attentionï¼Œä¸‹é¢ä»‹ç»å…¶ä»–éƒ¨åˆ†ã€‚</p><h2 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h2><p>ä¹‹å‰çš„åšå®¢ä»‹ç»äº†Encoder-Decoderç»“æ„ï¼ŒTransformerä¹Ÿéµä»è¿™ç§ç»“æ„ã€‚è€ŒTransformerâ€œæµ‘èº«éƒ½æ˜¯å®â€ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½è¢«å¼€å‘å‡ºäº†ä½œç”¨ï¼š</p><ul><li><strong>Transformerçš„Encoder</strong>ï¼ˆå¦‚<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">BERT</a>ï¼‰ï¼Œåˆç§°è‡ªç¼–ç  (auto-encoding) Transformer æ¨¡å‹</li><li><strong>Transformerçš„Decoder</strong>ï¼ˆå¦‚<a target="_blank" rel="noopener" href="https://openai.com/blog/language-unsupervised/">GPTç³»åˆ—</a>ï¼‰ï¼Œåˆç§°è‡ªå›å½’ (auto-regressive) Transformer æ¨¡å‹</li><li><strong>å®Œæ•´çš„Encoder-Decoder</strong>ï¼ˆä¾‹å¦‚<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1910.13461">BART</a>ã€<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1910.10683.pdf">T5</a>ç­‰ï¼‰</li></ul><p>ç†è§£äº†Transformerï¼Œä»¥ä¸Šæ¨¡å‹çš„ä¸Šæ‰‹éš¾åº¦ä¼šå°å¾ˆå¤šï¼Œæˆ‘ä»¬ä¹‹åå†äº†è§£ã€‚Transformeræ•´ä½“ç»“æ„å¦‚å›¾ï¼š</p><p><img src="/imgs/transformer.jpeg" alt="transformer"></p><p>å·¦è¾¹æ˜¯Encoderï¼Œå³è¾¹æ˜¯Decoderï¼Œå¯ä»¥çœ‹åˆ°ä¸¤è¾¹éƒ½æœ‰ï¼š</p><ul><li>Positional Encoding</li><li>Multi-head Attention</li><li>Feed Forward</li><li>Add &amp; Normã€‚</li></ul><p>Multi-head Attentionå·²ç»åœ¨ä¸Šæ–‡ä»‹ç»äº†ï¼Œä»‹ç»ä¸‹å…¶ä»–å‡ ä½ã€‚</p><h3 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h3><p>åœ¨Attentionä¸­å…¶å®å¯ä»¥çœ‹å‡ºï¼Œå¹¶æ²¡æœ‰ä»»ä½•æœ‰å…³ä½ç½®çš„ç‰¹å¾ï¼Œè¿™æ ·â€ä¸€æ­¥ä¸¤æ­¥ä¸‰æ­¥å››æ­¥æœ›ç€å¤©â€œçš„æ¯ä¸€ä¸ªâ€æ­¥â€œå‘é‡éƒ½æ˜¯ä¸€æ ·çš„ï¼Œç”šè‡³æŠŠè¿™å¥è¯å˜æˆâ€å¤©ç€æœ›æ­¥å››æ­¥ä¸‰æ­¥ä¸¤æ­¥â€ä¸€â€œï¼Œéƒ½æ˜¯ä¸€æ ·çš„ï¼Œè¿™æ˜¾ç„¶ä¸åˆç†ã€‚å› ä¸ºæ¯ä¸€æ­¥æƒ…ç»ªéƒ½æ˜¯é€’è¿›çš„ï¼Œè€ŒAttentionæ— æ³•è§£å†³å‰åé¡ºåºå’Œå¥å­å†…çš„ä¸€è¯å¤šä¹‰ã€‚</p><p>RNNé€šè¿‡è®°å¿†ä½¿å¾—æ¯ä¸€æ­¥ä¸ä¸€æ ·ï¼Œè€ŒTransformeré‡‡ç”¨äº†<em>Positional Encoding</em>ï¼Œå³ä½ç½®ç¼–ç ï¼Œå…¶å…¬å¼å¦‚ä¸‹ï¼š</p><p>$$<br>\begin{gather}<br>PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})\<br>PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})<br>\end{gather}<br>$$</p><p>æ„æ€å°±æ˜¯å‘é‡çš„å¶æ•°ä½ç½®å¡«$$sin$$ï¼Œå¥‡æ•°ä½ç½®å¡«$$cos$$ï¼Œ$$pos$$æŒ‡ç›¸å¯¹ä½ç½®ï¼Œå¦‚â€é’èŠ±ç“·â€œçš„â€é’â€œçš„$$pos$$å°±æ˜¯0ã€‚å¯¹â€é’èŠ±ç“·â€œè¿™ä¸‰ä¸ª10ç»´çš„å‘é‡è¿›è¡Œä½ç½®ç¼–ç ï¼Œç®€å•å®ç°ä»£ç å¦‚ä¸‹ï¼š</p><pre><code class="python">import math
import torch

seq_len = 3
d_model = 10
pe = torch.zeros(seq_len, d_model)
position = torch.arange(0, seq_len).unsqueeze(1)
div_term = torch.exp(torch.arange(0, d_model, 2) *
                     -math.log(10000.0) / d_model)
pe[:, 0::2] = torch.sin(position * div_term)
pe[:, 1::2] = torch.cos(position * div_term)
print(pe)
</code></pre><p>ç”±äºæ¬¡æ–¹æ¯”è¾ƒéš¾ç®—ï¼Œåˆ©ç”¨$e^{lnx}=x$çš„æ€§è´¨ï¼Œä»£ç ä¸­è¿›è¡Œäº†å¦‚ä¸‹è½¬æ¢ï¼š</p><p>$$<br>\frac{1}{10000^{2i/d}}<br>=e^{ln\frac{1}{10000^{2i/d}}}<br>=e^{-\frac{2i}{d}ln10000}<br>$$</p><p>å¾—åˆ°çš„PEçŸ©é˜µç”¨æ¥åŠ ä¸ŠåŸå§‹çš„è¯å‘é‡ã€‚ä½ç½®ç¼–ç ç›¸å½“äºæ ¹æ®ä½ç½®ç»™æƒé‡ã€‚ä¸ºä»€ä¹ˆè¿™ä¹ˆåšï¼Ÿæˆ‘ä»¬ä»0å¼€å§‹æ€è€ƒï¼Œè®©æˆ‘è®¾è®¡ä½ç½®ç¼–ç ï¼Œæ€ä¹ˆè®¾è®¡ï¼Ÿ</p><p>$$<br>ä¸€æ­¥ä¸¤æ­¥ä¸‰æ­¥å››æ­¥æœ›ç€å¤©:[0,1,2,3,4,5,6,7,8,9,10]<br>$$</p><p>é—®é¢˜åœ¨å“ªï¼Ÿè·Ÿembeddingå‘é‡çš„æ•°å­—ç›¸æ¯”ï¼Œè¿™ä¸ªæ•°å­—å¤ªå¤§äº†ï¼Œé‚£å½’ä¸€åŒ–ä¸€ä¸‹ï¼š</p><p>$$<br>ä¸€æ­¥ä¸¤æ­¥ä¸‰æ­¥å››æ­¥æœ›ç€å¤©:[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]<br>$$</p><p>è¿™æ ·çš„é—®é¢˜åœ¨äºæ— æ³•ä½“ç°ä½ç½®å…³ç³»ï¼Œå› ä¸ºæ³¨æ„åŠ›æ˜¯ç›¸ä¹˜ï¼Œä¸‹é¢é‡‡å–ç›¸ä¹˜ï¼š$0.1 \times 1=0.2 \times 0.5$ï¼Œä¸åŒè·ç¦»ç›¸ä¹˜å±…ç„¶ä¸€æ ·ï¼Œåä¹‹ï¼Œç›¸åŒè·ç¦»ç›¸ä¹˜å±…ç„¶ä¸ä¸€æ ·ã€‚å¤§æ¦‚æœ‰å¤´ç»ªäº†ï¼Œä½ç½®ç¼–ç èµ·ç éœ€è¦æ»¡è¶³è¿™äº›æ¡ä»¶ï¼šSSS</p><ol><li>ç›¸åŒè·ç¦»ç›¸ä¹˜ä¸€æ ·ï¼›</li><li>ä¸åŒè·ç¦»ç›¸ä¹˜ä¸ä¸€æ ·ï¼›</li><li>æ•°é‡ä¸é™ï¼šåºåˆ—æ— è®ºå¤šé•¿éƒ½èƒ½æ‰¾åˆ°ç›¸åº”çš„ä½ç½®ç¼–ç è¡¨ç¤ºã€‚</li></ol><p>Transformeræœ¬èº«æ˜¯åŠ å…¥é¢å¤–çš„ä½ç½®ï¼Œè¯å‘é‡åŠ ä¸Šä½ç½®çš„<strong>ç»å¯¹ä½ç½®ç¼–ç </strong>ã€‚å¦å¤–ï¼Œè¿˜æœ‰ä¿®æ”¹Attentionç»“æ„çš„<strong>ç›¸å¯¹ä½ç½®ç¼–ç </strong>ã€‚è€Œä¸‹é¢ä»‹ç»è‹ç¥çš„<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2104.09864">Rope</a>ç»“åˆäº†ä¸¤è€…ã€‚</p><h4 id="Ropeä½ç½®ç¼–ç "><a href="#Ropeä½ç½®ç¼–ç " class="headerlink" title="Ropeä½ç½®ç¼–ç "></a>Ropeä½ç½®ç¼–ç </h4><p>æ ¹æ®Transformerçš„ä½ç½®ç¼–ç å…¬å¼ï¼Œ$pos+k$ä½ç½®çš„ç¼–ç å¦‚ä¸‹ï¼š</p><p>$$<br>\begin{gather}<br>PE_{(pos+k,2i)}=sin((pos+k)/10000^{2i/d_{model}})\<br>PE_{(pos+k,2i+1)}=cos((pos+k)/10000^{2i/d_{model}})<br>\end{gather}<br>$$</p><p>å…ˆä»¤$w_i=1/10000^{2i/d_{model}}$ï¼Œæ ¹æ®ï¼š</p><p>$$<br>\begin{gather}<br>sin(\alpha+\beta)=sin\alpha \cdot cos\beta+cos\alpha \cdot sin\beta\<br>cos(\alpha+\beta)=cos\alpha \cdot cos\beta-sin\alpha \cdot sin\beta<br>\end{gather}<br>$$</p><p>æ¨å¯¼å‡ºï¼š</p><p>$$<br>\begin{gather}<br>PE_{(pos+k,2i)}=sin(w_i(pos+k))=sin(w_ipos) \cdot cos(w_ik)+cos(w_ipos) \cdot sin(w_ik)\<br>PE_{(pos+k,2i+1)}=cos(w_i(pos+k))=cos(w_ipos) \cdot cos(w_ik)-sin(w_ipos) \cdot sin(w_ik)<br>\end{gather}<br>$$</p><p>å°±æ˜¯å¤šäº†$k$çš„éƒ¨åˆ†ï¼Œå¯ä»¥è¡¨ç¤ºä¸ºçŸ©é˜µï¼š</p><p>$$<br>\begin{bmatrix}<br>PE_{(pos+k,2i)} \<br>PE_{(pos+k,2i+1)}<br>\end{bmatrix}<br>=<br>\begin{bmatrix}<br>cos(w_ik) &amp; sin(w_ik) \<br>-sin(w_ik) &amp; cos(w_ik)<br>\end{bmatrix}<br>\times<br>\begin{bmatrix}<br>PE_{(pos,2i)} \<br>PE_{(pos,2i+1)}<br>\end{bmatrix}<br>$$</p><p>ä»¤:</p><p>$$<br>R_k=<br>\begin{bmatrix}<br>cos(w_ik) &amp; sin(w_ik) \<br>-sin(w_ik) &amp; cos(w_ik)<br>\end{bmatrix}^T<br>$$</p><p>æ ¹æ®ï¼š</p><p>$$<br>\begin{gather}<br>-sinx=sin-x \<br>cosx=cos-x<br>\end{gather}<br>$$</p><p>æ˜“å¾—ï¼š</p><p>$$<br>R_k = R_{-k}^T<br>$$</p><p>å¹¶æœ‰å¦‚ä¸‹æ€§è´¨ï¼Œä»è€Œå¯ä»¥è¡¨ç¤ºç›¸å¯¹ä½ç½®ï¼š</p><p>$$<br>R_{k_2-k_1}=R_{k_1}^TR_{k_2}<br>$$</p><p>å¯¹ä½ç½®ä¸º$m$çš„è¯å‘é‡$A$å’Œä½ç½®ä¸º$n$çš„$B$ï¼Œå¯¹ä»–ä»¬ä¹˜ä¸Š$R_m$å’Œ$R_n$ï¼Œå°±ç»™AttentionåŠ ä¸Šäº†ç»å¯¹ä½ç½®ä¿¡æ¯ï¼Œå¹¶ä¸”å…·æœ‰$m-n$çš„ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼š</p><p>$$<br>AR_m(BR_n)^T=AR_mR_n^TB=AR_{n-m}B<br>$$</p><p>Ropeè¢«è®¸å¤šå¤§æ¨¡å‹å¦‚<a target="_blank" rel="noopener" href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">LLaMA</a>ã€<a target="_blank" rel="noopener" href="https://huggingface.co/tiiuae/falcon-40b-instruct">falcon</a>ç­‰é‡‡ç”¨ã€‚ä»¥å¾€è¾ƒå¤šæ¨¡å‹é‡‡ç”¨ç›´æ¥embedding+å­¦ä¹ çš„æ–¹å¼ï¼Œä½†æ˜¯è¿™æ ·æœ€å¼€å§‹å°±å®šæ­»äº†é•¿åº¦ï¼Œé‡åˆ°é•¿æ–‡æœ¬åªèƒ½æˆªæ–­ï¼Œè€ŒRopeæ”¹è‰¯äº†è¿™ä¸€ç‚¹ï¼Œä½¿å¾—å¤§æ¨¡å‹å…·æœ‰å¤„ç†è¶…é•¿æ–‡æœ¬çš„èƒ½åŠ›ã€‚æ›´å¤šä½ç½®ç¼–ç æ–¹å¼ï¼Œå¯ä»¥å‚è€ƒè‹ç¥çš„åšå®¢<a target="_blank" rel="noopener" href="https://kexue.fm/archives/8130">ã€Šè®©ç ”ç©¶äººå‘˜ç»å°½è„‘æ±çš„Transformerä½ç½®ç¼–ç ã€‹</a>ã€‚</p><h3 id="Feed-Forward"><a href="#Feed-Forward" class="headerlink" title="Feed Forward"></a>Feed Forward</h3><p>Feed Forwardç®€ç§°FFNï¼Œåœ¨Encoderå’ŒDecoderçš„å‹è½´å¤„éƒ½å„æœ‰ä¸€å±‚ï¼Œç”±ä¸¤ä¸ªå…¨è¿æ¥å’Œ<a target="_blank" rel="noopener" href="https://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf">ReLU</a>æ¿€æ´»å‡½æ•°ç»„æˆï¼Œå¦‚ä¸‹å¼ï¼š</p><p>$$<br>FFN(X)=max(0,xW_1+b_1)W_2+b_2<br>$$</p><p>è¿™ä¸ª$$max$$å°±æ˜¯ReLUã€‚å„ä¸ªæ¿€æ´»å‡½æ•°å¦‚å›¾ï¼š</p><p><img src="/imgs/Activation_Functions.gif" alt="Activation"></p><p>ReLUçš„å¯¼æ•°åªæœ‰0å’Œ1ï¼Œä½¿å¾—è®¡ç®—æˆæœ¬å¾ˆä½ã€‚</p><p>ä¸¤å±‚å…¨è¿æ¥æŠŠæ¨¡å‹ç»´åº¦ä»512æ‰©å±•åˆ°äº†2048åˆå›åˆ°512ã€‚æˆ‘æ‰¾éäº†åŸæ–‡å’Œå„ä¸ªæ•™ç¨‹ï¼Œéƒ½æ²¡æœ‰è¯¦ç»†è§£é‡Šè¿™ä¸€æ­¥çš„ä½œç”¨ã€‚</p><p>ä¸ªäººç†è§£å¯èƒ½æ˜¯æ‰©å±•åˆ°æ›´é«˜ç»´åº¦ä»¥å‚¨å­˜æ›´å¤šä¿¡æ¯ï¼Œä½†ä¹‹å‰è¿™ä¹ˆå¤šå‚æ•°è¿˜ä¸å¤Ÿï¼Ÿ</p><p>ä¹Ÿå¯èƒ½æ˜¯åŠ ä¸ªæ¿€æ´»å‡½æ•°ï¼Œä½†æ˜¯ä¹‹å‰ä¹Ÿæœ‰Softmaxã€‚</p><p>æœ‰åŠ å…¥ç±»ä¼¼å±‚è¿›è¡Œè°ƒå‚çš„å·¥ä½œï¼š<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1902.00751">adapter</a>ï¼Œä½†å…¶çœŸå®è®¾è®¡æ„å›¾æ˜¯ä»€ä¹ˆï¼Œä¹Ÿä¸å¾—è€ŒçŸ¥äº†ã€‚</p><h3 id="Add-amp-Norm"><a href="#Add-amp-Norm" class="headerlink" title="Add &amp; Norm"></a>Add &amp; Norm</h3><p>Add &amp; Normç”±Addå’ŒNormä¸¤éƒ¨åˆ†ç»„æˆã€‚</p><p>Addæ˜¯å°†ç®­å¤´æŒ‡è¿‡æ¥çš„ä¸¤è€…ç›¸åŠ ï¼ŒåŒ…æ‹¬Attentionå’ŒåŸembeddingè¿™ä¸¤ä¸ªçŸ©é˜µç›¸åŠ ã€ä»¥åŠè¿‡äº†FFNå’Œæ²¡è¿‡ä¹‹å‰çš„çŸ©é˜µç›¸åŠ ï¼Œè¿™ä¸ªå¾ˆç®€å•ï¼Œå°±ä¸ç»†è¯´äº†ã€‚</p><p>NormæŒ‡æ ‡å‡†åŒ–ï¼ŒTransformerä¸­ä½¿ç”¨<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">LayerNorm</a>ï¼Œåœ¨å›¾åƒé¢†åŸŸå¸¸ä½¿ç”¨BatchNormï¼Œä¸¤è€…éƒ½æ˜¯æ‹¿å‡å€¼æ–¹å·®åšæ ‡å‡†åŒ–å¤„ç†ï¼Œéƒ½æ˜¯ä¸‹å¼ï¼š</p><p>$$<br>y=\frac{x-E[x]}{\sqrt{Var[x]+\epsilon }}<br>$$</p><p>å…¶ä¸­$$E[x]$$ä¸ºå‡å€¼ï¼Œ$$Var[x]$$ä¸ºæ–¹å·®ï¼Œ$$\epsilon$$æ˜¯ä¸€ä¸ªå¾ˆå°çš„å¸¸æ•°ï¼Œç”¨äºé¿å…åˆ†æ¯ä¸ºé›¶ã€‚åŒºåˆ«å°±åœ¨äºä¸¤è€…æ‹¿æ¥ç®—å‡å€¼æ–¹å·®çš„æ•°ä¸ä¸€æ ·ï¼Œå¦‚ä¸‹ï¼š</p><ul><li>LayerNormçš„å‡å€¼æ–¹å·®ï¼Œæ˜¯å¯¹å•ä¸ªæ ·æœ¬çš„ä¸åŒç‰¹å¾åšæ“ä½œï¼Œå³æ¯ä¸ªè¯å‘é‡å†…éƒ¨ï¼›</li><li>BatchNormæ˜¯å¯¹ä¸åŒæ ·æœ¬çš„åŒä¸€ç‰¹å¾åšæ“ä½œã€‚</li></ul><p>æ‹¿â€œé’èŠ±ç“·â€çš„ç›¸ä¼¼çŸ©é˜µä¸ºä¾‹ï¼Œæ‰‹æ¨LayerNormï¼š</p><pre><code class="python">import torch.nn as nn
import math
matrix = torch.Tensor([[3.2897, 0.7432, -1.1652],
                       [0.7432, 1.3647, -1.1707],
                       [-1.1652, -1.1707, 5.6380]])
# torchå®˜æ–¹çš„layer_norm
layer_norm = nn.LayerNorm(matrix.shape[-1])
y_torch = layer_norm(matrix)
print(y_torch)
# åˆå§‹åŒ–ä¸€ä¸ªä¸matrixå¤§å°ç›¸åŒçš„å…¨0çŸ©é˜µ
y_ours = torch.zeros_like(matrix)
# æ‰‹æ¨å‡å€¼æ–¹å·®å’ŒLayerNorm
for row in range(matrix.shape[0]):
    E = sum(matrix[row]) / len(matrix[row])
    Var = 0
    for col in range(matrix.shape[1]):
        Var += (matrix[row, col] - E) ** 2 / len(matrix[row])
    for col in range(matrix.shape[1]):
        y_ours[row, col] = (matrix[row, col] - E) / math.sqrt(Var + 1e-5)
print(y_ours)
</code></pre><p>æ±‚å¾—çš„ç»“æœæ˜¯ä¸€æ ·çš„ã€‚å¯ä»¥çœ‹åˆ°ç»“æœä¸­ï¼Œæœ‰å°äº0ä¹Ÿæœ‰å¤§äº1çš„ï¼Œå› æ­¤æˆ‘è®¤ä¸ºæœ‰äº›æ•™ç¨‹ç§°ä¹‹ä¸ºâ€œå½’ä¸€åŒ–â€æ˜¯ä¸åˆç†çš„ï¼Œå½’ä¸€åŒ–æ˜¯é€šè¿‡MinMaxå°†æ‰€æœ‰æ•°æ®è½¬æ¢è‡³0-1èŒƒå›´å†…ã€‚è€ŒLayerNormï¼Œæ˜æ˜¾æ˜¯å‡å€¼0æ–¹å·®1çš„<strong>æ ‡å‡†åŒ–</strong>ã€‚</p><p>BatchNormçš„ä»£ç å¦‚ä¸‹ï¼š</p><pre><code class="python">import torch.nn as nn
import math
matrix = torch.Tensor([[3.2897, 0.7432, -1.1652],
                       [0.7432, 1.3647, -1.1707],
                       [-1.1652, -1.1707, 5.6380]])
layer_norm = nn.BatchNorm1d(matrix.shape[-1])
y_batch = layer_norm(matrix)
print(y_batch)
y_ours = torch.zeros_like(matrix)
# æ‰‹åŠ¨æ±‚å‡å€¼æ–¹å·®å’Œnorm
for col in range(matrix.shape[1]):
    E = sum(matrix[:, col]) / len(matrix[:, col])
    Var = 0
    for row in range(matrix.shape[0]):
        Var += (matrix[row, col] - E) ** 2 / len(matrix[row])
    for row in range(matrix.shape[1]):
        y_ours[row, col] = (matrix[row, col] - E) / math.sqrt(Var + 1e-5)
print(y_ours)
</code></pre><p>å·®åˆ«å°±åœ¨äºLayerNormåœ¨è¡Œï¼ŒBatchNormåœ¨åˆ—ã€‚</p><p>Transformer ä¸ºä»€ä¹ˆä½¿ç”¨ Layerï¼Ÿè¿™ä¸ªé—®é¢˜è¿˜æ²¡æœ‰å•¥å®šè®ºï¼ŒåŒ…æ‹¬LNå’ŒBNä¸ºå•¥èƒ½workä¹Ÿä¼—è¯´çº·çº­ï¼Œæ„Ÿå…´è¶£çš„è¯å¯ä»¥å‚è€ƒ<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1607.06450">åŸæ–‡</a>å’Œä»¥ä¸‹è®ºæ–‡ï¼š</p><ul><li>PowerNorm: Rethinking Batch Normalization in Transformers <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2003.07845">[1]</a></li><li>Understanding and Improving Layer Normalization <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.07013">[2]</a></li></ul><p>äº†è§£Transformerè¿™äº›åŸºæœ¬ç»„ä»¶åï¼Œè¿˜æœ‰å€¼å¾—æ¢è®¨çš„æ˜¯Maskã€‚</p><h3 id="Transformerä¸­çš„Mask"><a href="#Transformerä¸­çš„Mask" class="headerlink" title="Transformerä¸­çš„Mask"></a>Transformerä¸­çš„Mask</h3><p>æ­¤Maskéå½¼BERTçš„çš„é‚£ä¸ªæ©ç Maskã€‚è¿™é‡Œçš„MaskæŒ‡Pad Maskå’ŒAttention Maskã€‚</p><p>åœ¨<strong>Encoder</strong>ä¸­ï¼ŒPad Maskéœ€è¦å»æ‰$$<pad>$$çš„è®¡ç®—ã€‚ä»€ä¹ˆæ˜¯$$<pad>$$å‘¢ï¼Ÿä¸ºäº†å¹¶è¡Œè®¡ç®—æé«˜è®­ç»ƒé€Ÿåº¦ï¼Œé€šå¸¸æŠŠæ•°æ®æ‰“åŒ…æˆbatchï¼Œä¸€æ‰¹æ‰¹è®­ç»ƒï¼Œä¾‹å¦‚ä¸€ä¸ªbatchï¼š</pad></pad></p><ul><li>[â€œé’èŠ±ç“·â€, â€œçˆ±åœ¨è¥¿å…ƒå‰â€, â€œæ˜Ÿæ™´â€]</li></ul><p>ä½†æ˜¯æ¨¡å‹åªèƒ½å¤„ç†é•¿åº¦ç›¸åŒçš„å¥ï¼Œäºæ˜¯ç”¨&lt;pad&gt;å¡«å……åˆ°ç›¸åŒé•¿åº¦</p><ul><li>[â€œé’èŠ±ç“·$$<pad><pad>$$â€, â€œçˆ±åœ¨è¥¿å…ƒå‰â€, â€œæ˜Ÿæ™´$$<pad><pad><pad>$$â€]</pad></pad></pad></pad></pad></li></ul><p>è®¡ç®—æ—¶æŠŠ$$<pad>$$çš„ä½ç½®è®¾ç½®æˆè´Ÿæ— ç©·ï¼Œsoftmaxçš„å€¼å°±è¶‹äº0ï¼Œä»è€Œå¿½ç•¥ã€‚</pad></p><p>åœ¨<strong>Decoder</strong>ä¸­åŒæ ·è¦Pad Maskï¼Œé™¤æ­¤ä¹‹å¤–è¿˜éœ€è¦Attention Maskæ¥é®ä½åé¢çš„è¯ã€‚ä¾‹å¦‚è®­ç»ƒæ—¶æ–‡æœ¬æ˜¯â€œæ˜Ÿæ™´â€ï¼Œæ ‡ç­¾æ˜¯â€œä¹˜ç€é£â€ï¼Œè™½ç„¶çŸ¥é“æ ‡ç­¾å…¨å¥â€œä¹˜ç€é£â€ï¼Œä½†æ˜¯æ¨ç†æ—¶æ˜¯ä¸€ä¸ªè¯ä¸€ä¸ªè¯é¢„æµ‹çš„ï¼ŒDecoderé¢„æµ‹å‡ºâ€œä¹˜â€æ—¶ï¼Œå¹¶ä¸çŸ¥é“åé¢æ˜¯â€œç€é£â€ã€‚ä¸ºäº†åœ¨è®­ç»ƒæ—¶é€‚é…æ¨ç†ï¼Œé¢„æµ‹â€œç€â€æ—¶éœ€è¦æŠŠâ€œç€é£â€ç»™Maskï¼Œä¹Ÿå°±æ˜¯å»æ‰â€œä¹˜â€ä¸â€œç€â€ã€â€œé£â€çš„ç›¸ä¼¼åº¦ã€‚</p><p>â€ä¹˜ç€é£$$<pad><pad>$$â€œçš„Attention MaskçŸ©é˜µå¦‚å›¾ï¼š</pad></pad></p><p>$$<br>\begin{matrix}<br>1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\<br>1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\<br>1 &amp; 1 &amp; 1 &amp; 0 &amp; 0\<br>1 &amp; 1 &amp; 1 &amp; 0 &amp; 0\<br>1 &amp; 1 &amp; 1 &amp; 0 &amp; 0\<br>\end{matrix}<br>$$</p><p>å¯¹åº”ç›¸ä¼¼åº¦çŸ©é˜µ0çš„ä½ç½®ä¼šè¢«æ›¿æ¢æˆè´Ÿæ— ç©·ï¼Œsoftmaxåå€¼å°±è¶‹äº0ï¼Œä»è€Œä½¿å¾—AttentionçŸ©é˜µç¬¬ä¸€è¡Œå°±åªæœ‰ç¬¬ä¸€ä¸ªå­—çš„æƒé‡ï¼Œç¬¬äºŒè¡Œæœ‰ä¸€äºŒä¸¤ä¸ªå­—çš„æƒé‡ï¼Œä»¥æ­¤ç±»æ¨ã€‚</p><h3 id="Transformerå…¨è§ˆ"><a href="#Transformerå…¨è§ˆ" class="headerlink" title="Transformerå…¨è§ˆ"></a>Transformerå…¨è§ˆ</h3><p>ç»“åˆä¸Šè¿°æ‰€æœ‰ç»„ä»¶ï¼Œå¯¹ç…§ç€æ¨¡å‹å›¾ï¼Œå¯¹Transformeråšä¸ªå…¨è§ˆã€‚</p><p><img src="/imgs/transformer.jpeg" alt="transformer"></p><p>Encoderçš„æµç¨‹å¦‚ä¸‹ï¼š</p><ol><li><p>è¾“å…¥æ˜¯<strong>â€œæ˜Ÿæ™´â€</strong>ï¼Œå…ˆæ ¹æ®è¯è¡¨è½¬åŒ–ä¸º2ä¸ªå‘é‡çš„çŸ©é˜µ</p></li><li><p>åŠ ä¸Šä½ç½®ä¿¡æ¯</p></li><li><p>è¿‡Self-Attention</p></li><li><p>å’Œæ²¡è¿‡Self-Attentionçš„çŸ©é˜µç›¸åŠ ï¼Œç„¶åLayerNormæ ‡å‡†åŒ–</p></li><li><p>è¿‡FFNï¼Œå†å’Œæ²¡è¿‡FFNçš„çŸ©é˜µç›¸åŠ ï¼Œç„¶åLayerNormæ ‡å‡†åŒ–</p></li><li><p>å¾—åˆ°è·Ÿè¾“å…¥å‘é‡ç»´åº¦ä¸€æ ·çš„EncoderçŸ©é˜µ</p></li></ol><p>ä¸ºäº†å‘Šè¯‰Decoderä»å“ªå¼€å§‹åˆ°å“ªç»“æŸï¼Œéœ€è¦æ·»åŠ å¼€å§‹ç¬¦å’Œç»“æŸç¬¦ï¼Œä¾‹å¦‚$$<sos>$$ï¼ˆstart of sentenceï¼‰å’Œ$$<eos>$$ï¼ˆend of sentenceï¼‰ã€‚Decoderè®­ç»ƒçš„æµç¨‹å¦‚ä¸‹ï¼š</eos></sos></p><ol><li>æ ‡ç­¾æ˜¯$$\text{trg} = [sos, x_1, x_2, x_3, eos]$$ï¼Œè¾“å…¥<code>trg[:-1]</code>ï¼Œå¦‚â€œ$$<sos>$$ä¹˜ç€é£â€ï¼Œæ ¹æ®è¯è¡¨è½¬åŒ–ä¸º4ä¸ªå‘é‡çš„çŸ©é˜µ</sos></li><li>åŠ ä¸Šä½ç½®ä¿¡æ¯</li><li>è¿‡<strong>Attention Maskäº†</strong>çš„Self-Attention</li><li>å’Œæ²¡è¿‡Self-Attentionçš„çŸ©é˜µç›¸åŠ ï¼Œç„¶åLayerNormæ ‡å‡†åŒ–</li><li><strong>å¾—åˆ°çš„çŸ©é˜µä½œä¸ºQï¼ŒEncoderçŸ©é˜µä½œä¸ºKVï¼ŒåšCross Attention</strong></li><li>å’Œæ²¡è¿‡<strong>Cross Attention</strong>çš„çŸ©é˜µç›¸åŠ ï¼Œç„¶åLayerNormæ ‡å‡†åŒ–</li><li>è¿‡FFNï¼Œå†å’Œæ²¡è¿‡FFNçš„çŸ©é˜µç›¸åŠ ï¼Œç„¶åLayerNormæ ‡å‡†åŒ–</li><li>**è¿‡ä¸€å±‚å…¨è¿æ¥å’ŒSoftmaxï¼Œå¾—åˆ°$$\text{output} = [y_0, y_1, y_2, y_3]$$**ï¼Œä¾‹å¦‚å¾—åˆ°â€œä¹˜ç€è½¦$$<eos>$$â€</eos></li><li>å¤šåˆ†ç±»é—®é¢˜ç”¨äº¤å‰ç†µè®¡ç®—<code>trg[1:]</code>å’Œ<code>output</code>é—´çš„æŸå¤±ã€æ›´æ–°å‚æ•°</li></ol><p>Decoderæ¨ç†æ—¶ï¼Œè¿™ä¸ªæµç¨‹å˜æˆï¼š</p><ol><li>å‘Decoderè¾“å…¥$$<sos>$$ï¼Œè¾“å‡º$$[y_0]$$</sos></li><li>åˆå¹¶å¾—$$[<sos>, y_0]$$ï¼Œç»§ç»­å‘Decoderè¾“å…¥ï¼Œå¾—$$[y_0^{â€˜}, y_1]$$</sos></li><li>åˆå¹¶å¾—$$[<sos>, y_0, y_1]$$ï¼Œä»¥æ­¤ç±»æ¨</sos></li><li>å½“é¢„æµ‹åˆ°$$<eos>$$ï¼Œæˆ–è€…è¾¾åˆ°è®¾ç½®çš„æœ€å¤§é•¿åº¦ï¼Œåœæ­¢</eos></li></ol><p>é€šè¿‡æœ¬ç« ï¼Œç›¸ä¿¡ä½ å·²ç»å¯¹ Transformer æ¨¡å‹çš„å®šä¹‰å’Œå‘å±•æœ‰äº†å¤§æ¦‚çš„äº†è§£ã€‚å¹¸è¿çš„æ˜¯ï¼Œ<a target="_blank" rel="noopener" href="https://huggingface.co/">Hugging Face</a> ä¸“é—¨ä¸ºä½¿ç”¨ Transformer æ¨¡å‹ç¼–å†™äº†ä¸€ä¸ª <a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/index">Transformers åº“</a>ï¼Œå¹¶ä¸”åœ¨<a target="_blank" rel="noopener" href="https://huggingface.co/models">Hugging Face Hub</a>ä¸­æä¾›äº†è®­ç»ƒå¥½çš„æ¨¡å‹ä»¥ä¾›å¿«é€Ÿä½¿ç”¨ã€‚</p><p>åœ¨åé¢çš„ç« èŠ‚ä¸­æˆ‘ä¼šæ‰‹æŠŠæ‰‹åœ°å¸¦ä½ ç¼–å†™å¹¶è®­ç»ƒè‡ªå·±çš„ Transformer æ¨¡å‹ã€‚</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a href="https://www.jkzhang.ml">JackZhang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="https://www.jkzhang.ml/2025/02/20/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%9C%80%E4%BC%98%E5%85%AC%E5%BC%8F/">https://www.jkzhang.ml/2025/02/20/%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%9C%80%E4%BC%98%E5%85%AC%E5%BC%8F/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://www.jkzhang.ml" target="_blank">JackZhang's Blog</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/deep-learning/">deep learning</a><a class="post-meta__tags" href="/tags/transformers/">transformers</a><a class="post-meta__tags" href="/tags/attention/">attention</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/02/22/#%20%E8%B4%9D%E5%B0%94%E6%9B%BC%E6%96%B9%E7%A8%8B/"><img class="cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info"></div></div></a></div><div class="next-post pull-right"><a href="/2024/06/13/Linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/" title="Linuxç›®å½•ç»“æ„"><img class="cover" src="https://s3.bmp.ovh/imgs/2024/06/13/e2aa614f45568c02.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">Linuxç›®å½•ç»“æ„</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s3.bmp.ovh/imgs/2024/06/07/50ea7f3f41ccf524.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">JackZhang</div><div class="author-info__description">äººï¼Œå¯ä»¥ç”Ÿå¦‚èšè€Œç¾å¦‚ç¥</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">63</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/zhangrongxiang" target="_blank" title="Github"><i class="fab fa-github" style="color:#24292e"></i></a><a class="social-icon" href="/2437603206@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color:#4a7dbe"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>å…¬å‘Š</span></div><div class="announcement_content">è¿™ä¸ªblogå·²ç»å¹´ä¹…å¤±ä¿®ï¼Œå…³äºæˆ‘çš„æ–‡ç« ï¼Œæ¬¢è¿æ¥CSDNè®¿é—® ğŸ¥°</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Attention%E7%9A%84%E6%80%9D%E6%83%B3"><span class="toc-number">1.</span> <span class="toc-text">Attentionçš„æ€æƒ³</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Self-Attention"><span class="toc-number">1.1.</span> <span class="toc-text">Self-Attention</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-head-Attention"><span class="toc-number">1.2.</span> <span class="toc-text">Multi-head Attention</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Encoder-Decoder"><span class="toc-number">2.</span> <span class="toc-text">Encoder-Decoder</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Positional-Encoding"><span class="toc-number">2.1.</span> <span class="toc-text">Positional Encoding</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Rope%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81"><span class="toc-number">2.1.1.</span> <span class="toc-text">Ropeä½ç½®ç¼–ç </span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Feed-Forward"><span class="toc-number">2.2.</span> <span class="toc-text">Feed Forward</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Add-amp-Norm"><span class="toc-number">2.3.</span> <span class="toc-text">Add &amp; Norm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformer%E4%B8%AD%E7%9A%84Mask"><span class="toc-number">2.4.</span> <span class="toc-text">Transformerä¸­çš„Mask</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformer%E5%85%A8%E8%A7%88"><span class="toc-number">2.5.</span> <span class="toc-text">Transformerå…¨è§ˆ</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>æœ€æ–°æ–‡ç« </span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/02/22/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E8%84%89%E7%BB%9C/" title="æ— é¢˜"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="æ— é¢˜"></a><div class="content"><a class="title" href="/2025/02/22/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E8%84%89%E7%BB%9C/" title="æ— é¢˜">æ— é¢˜</a><time datetime="2025-02-22T08:34:25.493Z" title="å‘è¡¨äº 2025-02-22 16:34:25">2025-02-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/22/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/" title="æ— é¢˜"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="æ— é¢˜"></a><div class="content"><a class="title" href="/2025/02/22/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95/" title="æ— é¢˜">æ— é¢˜</a><time datetime="2025-02-22T08:34:25.491Z" title="å‘è¡¨äº 2025-02-22 16:34:25">2025-02-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/22/%E6%94%B9%E5%8A%A8/" title="æ— é¢˜"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="æ— é¢˜"></a><div class="content"><a class="title" href="/2025/02/22/%E6%94%B9%E5%8A%A8/" title="æ— é¢˜">æ— é¢˜</a><time datetime="2025-02-22T08:34:25.490Z" title="å‘è¡¨äº 2025-02-22 16:34:25">2025-02-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/22/reward-to-go/" title="æ— é¢˜"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="æ— é¢˜"></a><div class="content"><a class="title" href="/2025/02/22/reward-to-go/" title="æ— é¢˜">æ— é¢˜</a><time datetime="2025-02-22T08:34:25.484Z" title="å‘è¡¨äº 2025-02-22 16:34:25">2025-02-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/22/##%20%E5%80%BC%E8%BF%AD%E4%BB%A3%20%20Value%20Iteration/" title="æ— é¢˜"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="æ— é¢˜"></a><div class="content"><a class="title" href="/2025/02/22/##%20%E5%80%BC%E8%BF%AD%E4%BB%A3%20%20Value%20Iteration/" title="æ— é¢˜">æ— é¢˜</a><time datetime="2025-02-22T08:34:25.479Z" title="å‘è¡¨äº 2025-02-22 16:34:25">2025-02-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By JackZhang</div><div class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>